{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a161816",
   "metadata": {},
   "source": [
    "# LangChain: Introduction and Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3902c",
   "metadata": {},
   "source": [
    "### LangChain\n",
    "At its core, LangChain is a framework built around LLMs. We can use it for chatbots, Generative Question-Answering (GQA), summarization, and much more.\n",
    "\n",
    "The core idea of the library is that we can “chain” together different components to create more advanced use cases around LLMs. Chains may consist of multiple components from several modules:\n",
    "\n",
    "Prompt templates: Prompt templates are templates for different types of prompts. Like “chatbot” style templates, ELI5 question-answering, etc\n",
    "LLMs: Large language models like GPT-3, BLOOM, etc\n",
    "Agents: Agents use LLMs to decide what actions should be taken. Tools like web search or calculators can be used, and all are packaged into a logical loop of operations.\n",
    "Memory: Short-term memory, long-term memory.\n",
    "We will dive into each of these in much more detail in upcoming chapters of the LangChain handbook.\n",
    "\n",
    "For now, we’ll start with the basics behind prompt templates and LLMs. We’ll also explore two LLM options available from the library, using models from Hugging Face Hub or OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa897fd5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (0.0.281)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from langchain) (0.0.33)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from langchain) (2.3.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from langchain) (2.29.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e347fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5456ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "        template=template,\n",
    "    input_variables=['question']\n",
    ")\n",
    "\n",
    "# user question\n",
    "question = \"Which NFL team won the Super Bowl in the 2010 season?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b8a96a",
   "metadata": {},
   "source": [
    "When using these prompt template with the given question we will get:\n",
    "\n",
    "Question: Which NFL team won the Super Bowl in the 2010 season? Answer:\n",
    "\n",
    "For now, that’s all we need. We’ll use the same prompt template across both Hugging Face Hub and OpenAI LLM generations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c9823e",
   "metadata": {},
   "source": [
    "# Hugging Face Hub LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae6386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ed2a55f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (0.15.1)\n",
      "Requirement already satisfied: filelock in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied: fsspec in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (2023.4.0)\n",
      "Requirement already satisfied: requests in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b4ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "befd3c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "san francisco 49ers\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "\n",
    "# initialize Hub LLM\n",
    "hub_llm = HuggingFaceHub(\n",
    "        repo_id='google/flan-t5-large',\n",
    "    model_kwargs={'temperature':1e-10}\n",
    ")\n",
    "\n",
    "# create prompt template > LLM chain\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=hub_llm\n",
    ")\n",
    "\n",
    "# ask the user question about NFL 2010\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18036d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask the user question about NFL 2010\n",
    "ans = llm_chain.run(\"Which NFL team won the Super Bowl in the 2010 season?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a72c7068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'san francisco 49ers'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be6c9b",
   "metadata": {},
   "source": [
    "# Asking Multiple Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04aaa4a",
   "metadata": {},
   "source": [
    "# If we’d like to ask multiple questions, we can try two approaches:\n",
    "\n",
    "If we’d like to ask multiple questions, we can try two approaches:\n",
    "\n",
    "- Iterate through all questions using the generate method, answering them one at a time.\n",
    "\n",
    "- Place all questions into a single prompt for the LLM; this will only work for more advanced LLMs.\n",
    "\n",
    " Starting with option (1), let’s see how to use the generate method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0cf1c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='san francisco 49ers', generation_info=None)], [Generation(text='76', generation_info=None)], [Generation(text='john glenn', generation_info=None)], [Generation(text='one', generation_info=None)]], llm_output=None, run=[RunInfo(run_id=UUID('abf0ae55-0d60-4c2e-898b-d2e4af549ec1')), RunInfo(run_id=UUID('478cefba-d9f5-41e3-bc93-ab2b36c6e274')), RunInfo(run_id=UUID('601bab7a-2f6a-4daf-9fc7-9bd26b41a7b2')), RunInfo(run_id=UUID('4c3de90c-41ff-444b-a583-d04227904bce'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = [\n",
    "    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n",
    "    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n",
    "    {'question': \"Who was the 12th person on the moon?\"},\n",
    "    {'question': \"How many eyes does a blade of grass have?\"}\n",
    "]\n",
    "res = llm_chain.generate(qs)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "992d4991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Green Bay Packers won the Super Bowl in the 2010 season. I am 193 centimeters tall if I am 6 ft 4 inches. Edwin \"Buzz\" Aldrin was the 12th person on the moon. A blade of grass does not have eyes.\n"
     ]
    }
   ],
   "source": [
    "multi_template = \"\"\"Answer the following questions one at a time.\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Answers:\n",
    "\"\"\"\n",
    "\n",
    "qs_str = (\n",
    "    \"Which NFL team won the Super Bowl in the 2010 season?\\n\" +\n",
    "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\\n\" +\n",
    "    \"Who was the 12th person on the moon?\" +\n",
    "    \"How many eyes does a blade of grass have?\"\n",
    ")\n",
    "print(llm_chain.run(qs_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a7f43",
   "metadata": {},
   "source": [
    "# OpenAI LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db62828",
   "metadata": {},
   "source": [
    "The OpenAI endpoints in LangChain connect to OpenAI directly or via Azure. We need an OpenAI account and API key to use these endpoints.\n",
    "\n",
    "Once you have an API key, we add it to the OPENAI_API_TOKEN environment variable. We can do this with Python like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4021db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e765ac9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from openai) (2.29.0)\n",
      "Requirement already satisfied: tqdm in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/abdul-qadir/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5472d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "davinci = OpenAI(model_name = 'text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aae6f1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Green Bay Packers won the Super Bowl in the 2010 season.\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=davinci\n",
    ")\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf4567c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text=' The Green Bay Packers won Super Bowl XLV in the 2010 season.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=' 193.04 cm', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=' The twelfth person to walk on the moon was astronaut Harrison Schmitt on Apollo 17 on December 11, 1972.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=' A blade of grass does not have any eyes.', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'prompt_tokens': 75, 'total_tokens': 126, 'completion_tokens': 51}, 'model_name': 'text-davinci-003'} run=[RunInfo(run_id=UUID('e1ba5f35-e11d-4a70-b3fc-678293d2cfd3')), RunInfo(run_id=UUID('805b70af-6be1-4b23-bbf9-716d86c3dae6')), RunInfo(run_id=UUID('f31f722e-2747-4a4c-a4d7-7bdba139a1c5')), RunInfo(run_id=UUID('da7ad66b-dde5-45d9-b918-8bddb11c2f39'))]\n"
     ]
    }
   ],
   "source": [
    "qs = [\n",
    "    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n",
    "    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n",
    "    {'question': \"Who was the 12th person on the moon?\"},\n",
    "    {'question': \"How many eyes does a blade of grass have?\"}\n",
    "]\n",
    "print(llm_chain.generate(qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a1ef533",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_template = \"\"\"Answer the following questions one at a time.\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Answers:\n",
    "\"\"\"\n",
    "long_prompt = PromptTemplate(template=multi_template, input_variables=[\"questions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8fa44f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The New Orleans Saints won the Super Bowl in the 2010 season.\n",
      "You are 193 cm tall if you are 6 ft 4 inches.\n",
      "The 12th person on the moon was Charles Duke.\n",
      "A blade of grass has no eyes.\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=davinci\n",
    ")\n",
    "\n",
    "qs_str = (\n",
    "    \"Which NFL team won the Super Bowl in the 2010 season?\\n\" +\n",
    "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\\n\" +\n",
    "    \"Who was the 12th person on the moon?\" +\n",
    "    \"How many eyes does a blade of grass have?\"\n",
    ")\n",
    "\n",
    "print(llm_chain.run(qs_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac63b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
